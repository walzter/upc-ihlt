{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing\n",
    "# TODO = [] \n",
    "\n",
    "## FEATURE ENGINEERING\n",
    "## Lexical Similarities:\n",
    "# FuzzyWuzzy []\n",
    "\n",
    "## MODEL\n",
    "# SVM \n",
    "\n",
    "## Data Augmentation\n",
    "# Back Translation => English --> Another Language --> English \n",
    "\n",
    "## Final Eval\n",
    "# Pearson []\n",
    "# Confidence Interval? []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Textual Similarity (STS) Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this project is to be able to determine the similarity between two sentences. One sentence is said to be \"parraphrased\" when the content (or message) is the same, but uses different words and or structure. \n",
    "\n",
    "An example from the trial set: \n",
    " - The bird is bathing in the sink.\n",
    "\n",
    " - Birdie is washing itself in the water basin.\n",
    "\n",
    "Here we are given a set of training and testing sets in which they are labeled with the \"gs\", on a scale of 0-5. \n",
    "\n",
    "|label|\tdescription|\n",
    "| :-: | :-: |\n",
    "|5\t| They are completely equivalent, as they mean the same thing.|\n",
    "|4\t| They are mostly equivalent, but some unimportant details differ.|\n",
    "|3\t| They are roughly equivalent, but some important information differs/missing.|\n",
    "|2\t| They are not equivalent, but share some details.|\n",
    "|1\t| They are not equivalent, but are on the same topic.|\n",
    "|0\t| They are on different topics.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create the following: \n",
    "- Read in the sentences as a total dataframe  --> Either load all three dataframes and then append them into a bigger one. \n",
    "- append the corresponding GS to the dataframe  --> Add this one to the previous df \n",
    "- Create a utils file in which we have all the features we want to create\n",
    "- Show which features were created and how/why \n",
    "- we can then create a pipeline\n",
    "    - Takes in all the features from before and makes them into a feature array \n",
    "    - Standardizes the values \n",
    "    - Outputs a simple N-D array with all the processed / calculated features \n",
    "\n",
    "- We need to create 3 variations: \n",
    "    1. \"Standard\" distance similarities \n",
    "    2. \"XTRa Train\" --> With more training data doing back-translation and AEDA \n",
    "\n",
    "\n",
    "*STEPS:*\n",
    "1. Preprocess textual data \n",
    "    - Read in sentence pairs --> DONE\n",
    "    - Tokenize --> DONE\n",
    "    - Pos Tag ---> DONE\n",
    "    - Remove stopwords and punctuation  --> DONE\n",
    "\n",
    "2. Extract Features \n",
    "    - Similarity measures \n",
    "    - Word frequency \n",
    "    - Tf-IDF ?\n",
    "3. Generate Extra Data (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/Eric/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/Eric/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Eric/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /Users/Eric/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/Eric/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/Eric/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /Users/Eric/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet_ic to /Users/Eric/nltk_data...\n",
      "[nltk_data]   Package wordnet_ic is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "from nltk.metrics import jaccard_distance\n",
    "from fuzzywuzzy import fuzz\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.collocations import TrigramCollocationFinder\n",
    "from nltk.wsd import lesk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import sentiwordnet\n",
    "from nltk.corpus import wordnet_ic\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('wordnet_ic')\n",
    "# setting the wordnet_ic \n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/Eric/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Data Loader file with two functions\n",
    "from data_loader_ import *\n",
    "\n",
    "# Preprocessing file with several prerpocessing functions\n",
    "from pre_processing import *\n",
    "\n",
    "# feature extraction \n",
    "from feature_extractor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING PATH\n",
    "TRAIN_PATH = './data/train/input/'\n",
    "TRAIN_GS_PATH = './data/train/gs/'\n",
    "\n",
    "# TEST PATH\n",
    "TEST_PATH = 'data/test/input/'\n",
    "TEST_GS_PATH = './data/test/gs/'\n",
    "\n",
    "# Loading the Data \n",
    "X_train, y_train, X_test, y_test = load_sentences(TRAIN_PATH), load_gs(TRAIN_GS_PATH),load_sentences(TEST_PATH), load_gs(TEST_GS_PATH)\n",
    "\n",
    "#sepparating the sentences \n",
    "SA, SB = get_processed_sentences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a total of 2234 sentence pairs\n"
     ]
    }
   ],
   "source": [
    "# Lets look at how many total values we have\n",
    "print(f\"We have a total of {X_train.shape[0]} sentence pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jacc_nopunc</th>\n",
       "      <th>jacc_nopunc_stop</th>\n",
       "      <th>jacc_lemmas</th>\n",
       "      <th>fuzzy_ratio</th>\n",
       "      <th>lev_ratio</th>\n",
       "      <th>lev_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>90</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>89</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>89</td>\n",
       "      <td>0.894118</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>89</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>57</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>69</td>\n",
       "      <td>0.692913</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>67</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>57</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>66</td>\n",
       "      <td>0.663717</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2234 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     jacc_nopunc jacc_nopunc_stop jacc_lemmas fuzzy_ratio lev_ratio  \\\n",
       "0       0.666667              0.5         0.5          90  0.897959   \n",
       "1       0.888889                1           1          89  0.894737   \n",
       "2            0.5         0.333333    0.333333          89  0.894737   \n",
       "3            0.7              0.5         0.5          89  0.894118   \n",
       "4       0.714286              0.5         0.5          89  0.892857   \n",
       "...          ...              ...         ...         ...       ...   \n",
       "2229    0.318182         0.285714    0.285714          57  0.566667   \n",
       "2230    0.571429         0.714286    0.714286          69  0.692913   \n",
       "2231         0.5              0.4         0.4          67  0.666667   \n",
       "2232    0.263158         0.307692    0.416667          57  0.571429   \n",
       "2233    0.555556         0.533333         0.5          66  0.663717   \n",
       "\n",
       "     lev_distance  \n",
       "0               4  \n",
       "1               8  \n",
       "2               3  \n",
       "3               7  \n",
       "4               4  \n",
       "...           ...  \n",
       "2229           56  \n",
       "2230           32  \n",
       "2231           57  \n",
       "2232           62  \n",
       "2233           64  \n",
       "\n",
       "[2234 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Levenshtein as lev\n",
    "from fuzzywuzzy import fuzz\n",
    "# JACCARD SIMILARITY:\n",
    "\n",
    "# creating a copy \n",
    "X_features = X_train.copy()\n",
    "#dropping one of the columns \n",
    "X_features = X_features.drop('SentA',axis=1)\n",
    "# empty column to append the jacc distance \n",
    "X_features['jacc_nopunc'] = ''\n",
    "X_features['jacc_nopunc_stop'] = ''\n",
    "X_features['jacc_lemmas'] = ''\n",
    "X_features['fuzzy_ratio'] = ''\n",
    "X_features['lev_ratio'] = ''\n",
    "X_features['lev_distance'] = ''\n",
    "for index in X_features.index:\n",
    "  # no punctuation \n",
    "  X_features['jacc_nopunc'][index] = jd(SA['SentA_nopunc'][index], SB['SentB_nopunc'][index],is_set=True)\n",
    "  # no punctuation or stopwords \n",
    "  X_features['jacc_nopunc_stop'][index] = jd(SA['SentA_nopunc_stop'][index], SB['SentB_nopunc_stop'][index], is_set=True)\n",
    "  #lemmas \n",
    "  X_features['jacc_lemmas'][index] = jd(SA['SentA_lemmas'][index], SB['SentB_lemmas'][index],is_set=True)\n",
    "  # FuzzyWuzzy String Matching\n",
    "  X_features['fuzzy_ratio'][index] = fuzz.ratio(SA['SentA'][index].lower(), SB['SentB'][index].lower())\n",
    "  # Levenshtein Ratio \n",
    "  X_features['lev_ratio'][index] = lev.ratio(SA['SentA'][index].lower(), SB['SentB'][index].lower())\n",
    "  # Levenshtein Distance -> Number of edits for them to be the same \n",
    "  X_features['lev_distance'][index] = lev.distance(SA['SentA'][index].lower(), SB['SentB'][index].lower())\n",
    "  \n",
    "#dropping one of the columns \n",
    "X_features = X_features.drop('SentB',axis=1)\n",
    "X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jacc_nopunc</th>\n",
       "      <th>jacc_nopunc_stop</th>\n",
       "      <th>jacc_lemmas</th>\n",
       "      <th>fuzzy_ratio</th>\n",
       "      <th>lev_ratio</th>\n",
       "      <th>lev_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>90</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>89</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>89</td>\n",
       "      <td>0.894118</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>89</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>57</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>69</td>\n",
       "      <td>0.692913</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>67</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>57</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>66</td>\n",
       "      <td>0.663717</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2234 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     jacc_nopunc jacc_nopunc_stop jacc_lemmas fuzzy_ratio lev_ratio  \\\n",
       "0       0.666667              0.5         0.5          90  0.897959   \n",
       "1       0.888889                1           1          89  0.894737   \n",
       "2            0.5         0.333333    0.333333          89  0.894737   \n",
       "3            0.7              0.5         0.5          89  0.894118   \n",
       "4       0.714286              0.5         0.5          89  0.892857   \n",
       "...          ...              ...         ...         ...       ...   \n",
       "2229    0.318182         0.285714    0.285714          57  0.566667   \n",
       "2230    0.571429         0.714286    0.714286          69  0.692913   \n",
       "2231         0.5              0.4         0.4          67  0.666667   \n",
       "2232    0.263158         0.307692    0.416667          57  0.571429   \n",
       "2233    0.555556         0.533333         0.5          66  0.663717   \n",
       "\n",
       "     lev_distance  \n",
       "0               4  \n",
       "1               8  \n",
       "2               3  \n",
       "3               7  \n",
       "4               4  \n",
       "...           ...  \n",
       "2229           56  \n",
       "2230           32  \n",
       "2231           57  \n",
       "2232           62  \n",
       "2233           64  \n",
       "\n",
       "[2234 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extra features used: \n",
    "# FuzzyWuzzy String matching \n",
    "# Levenshtein Ratio \n",
    "# Levenshtein Distane \n",
    "\n",
    "X_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7b0227df9456bca28f69aef5d39629306c490f3d5d6e0ff9d2fd6f7d7f6a539"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
