{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Textual Similarity (STS) Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this project is to be able to determine the similarity between two sentences. One sentence is said to be \"parraphrased\" when the content (or message) is the same, but uses different words and or structure. \n",
    "\n",
    "An example from the trial set: \n",
    " - The bird is bathing in the sink.\n",
    "\n",
    " - Birdie is washing itself in the water basin.\n",
    "\n",
    "Here we are given a set of training and testing sets in which they are labeled with the \"gs\", on a scale of 0-5. \n",
    "\n",
    "|label|\tdescription|\n",
    "| :-: | :-: |\n",
    "|5\t| They are completely equivalent, as they mean the same thing.|\n",
    "|4\t| They are mostly equivalent, but some unimportant details differ.|\n",
    "|3\t| They are roughly equivalent, but some important information differs/missing.|\n",
    "|2\t| They are not equivalent, but share some details.|\n",
    "|1\t| They are not equivalent, but are on the same topic.|\n",
    "|0\t| They are on different topics.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader file with two functions: load_sentences \n",
    "from helper_funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING PATH\n",
    "TRAIN_PATH = './data/train/input/'\n",
    "TRAIN_GS_PATH = './data/train/gs/'\n",
    "# TEST PATH\n",
    "TEST_PATH = 'data/test/input/'\n",
    "TEST_GS_PATH = './data/test/gs/'\n",
    "\n",
    "# Loading the Data \n",
    "# --> COMMENT THESE LINES IF FILES ARE ALREADY PICKLED\n",
    "X_train, y_train, X_test, y_test = load_sentences(TRAIN_PATH), load_gs(TRAIN_GS_PATH),load_sentences(TEST_PATH), load_gs(TEST_GS_PATH)\n",
    "\n",
    "# X_train with extracted features and standardized values \n",
    "#X_train_scaled_norm = extract_features(X_train,scaled=True)\n",
    "# X_test with extracted features and standardized values \n",
    "#X_test_scaled_norm = extract_features(X_test,scaled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# pickle the files for later use if necesary as to not calculate more\n",
    "# saving the training features \n",
    "with open(\"./X_train_scaled_norm.pickle\",'wb') as f:\n",
    "    pickle.dump(X_train_scaled_norm,f,pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# saving the testing features \n",
    "with open(\"./X_test_scaled_norm.pickle\",'wb') as f:\n",
    "    pickle.dump(X_test_scaled_norm,f,pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the pickle files to avoid re-processing \n",
    "X_train_scaled_norm = pickle.load( open( \"X_train_scaled_norm.pickle\", \"rb\" ) )\n",
    "X_test_scaled_norm = pickle.load( open( \"X_test_scaled_norm.pickle\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from scipy.stats import pearsonr\n",
    "svr = SVR(kernel = 'rbf', gamma = 0.01, C = 200, epsilon = 0.50, tol = 0.25)\n",
    "svr.fit(X_train_scaled_norm, y_train.values.reshape(-1,))\n",
    "\n",
    "# Predict\n",
    "y_pred = svr.predict(X_test_scaled_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEARSON CORRELATION 0.7892\n"
     ]
    }
   ],
   "source": [
    "corr = pearsonr(y_pred, y_test.values.reshape(-1,))[0]\n",
    "print(f\"PEARSON CORRELATION {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between our model and baseline: 0.0330\n",
      "The percent change was 4.3661%\n"
     ]
    }
   ],
   "source": [
    "# checking the difference between the baseline \n",
    "baseline = 0.7562\n",
    "diff = corr - baseline\n",
    "pcnt_chng = ((corr-baseline) / (baseline) )*100\n",
    "print(f\"Difference between our model and baseline: {diff:.4f}\")\n",
    "print(f\"The percent change was {pcnt_chng:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7b0227df9456bca28f69aef5d39629306c490f3d5d6e0ff9d2fd6f7d7f6a539"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
