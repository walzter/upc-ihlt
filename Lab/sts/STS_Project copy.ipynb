{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Textual Similarity (STS) Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this project is to be able to determine the similarity between two sentences. One sentence is said to be \"parraphrased\" when the content (or message) is the same, but uses different words and or structure. \n",
    "\n",
    "An example from the trial set: \n",
    " - The bird is bathing in the sink.\n",
    "\n",
    " - Birdie is washing itself in the water basin.\n",
    "\n",
    "Here we are given a set of training and testing sets in which they are labeled with the \"gs\", on a scale of 0-5. \n",
    "\n",
    "|label|\tdescription|\n",
    "| :-: | :-: |\n",
    "|5\t| They are completely equivalent, as they mean the same thing.|\n",
    "|4\t| They are mostly equivalent, but some unimportant details differ.|\n",
    "|3\t| They are roughly equivalent, but some important information differs/missing.|\n",
    "|2\t| They are not equivalent, but share some details.|\n",
    "|1\t| They are not equivalent, but are on the same topic.|\n",
    "|0\t| They are on different topics.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader file with two functions: load_sentences \n",
    "from helper_funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING PATH\n",
    "TRAIN_PATH = './data/train/input/'\n",
    "TRAIN_GS_PATH = './data/train/gs/'\n",
    "# TEST PATH\n",
    "TEST_PATH = 'data/test/input/'\n",
    "TEST_GS_PATH = './data/test/gs/'\n",
    "# Loading the Data \n",
    "X_train, y_train, X_test, y_test = load_sentences(TRAIN_PATH), load_gs(TRAIN_GS_PATH),load_sentences(TEST_PATH), load_gs(TEST_GS_PATH)\n",
    "# X_train with extracted features and standardized values \n",
    "X_train_scaled_norm = extract_features(X_train,scaled=True)\n",
    "# X_test with extracted features and standardized values \n",
    "X_test_scaled_norm = extract_features(X_test,scaled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sepparating the sentences \n",
    "SA, SB = get_processed_sentences(X_train)\n",
    "# Jaccard_Fuzzy_Lev\n",
    "feature_df = jd_fuzz_lev(SA, SB, X_train)\n",
    "#unigram, bigram and trigram features\n",
    "ngram_features = get_ngram_features(SA,SB)\n",
    "#features related to the length\n",
    "length_features = get_length_features(SA,SB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.svm import SVR\n",
    "from scipy.stats import pearsonr\n",
    "svr = SVR(kernel = 'rbf', gamma = 0.01, C = 200, epsilon = 0.50, tol = 0.25)\n",
    "svr.fit(X_scaled, y_train.values.reshape(-1,))\n",
    "\n",
    "# Predict\n",
    "test_predict = svr.predict(X_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = pearsonr(test_predict, y_test.values.reshape(-1,))[0]\n",
    "print(\"Pearson correlation:\", correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRIDSEARCH\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param = {'kernel' : ('rbf'),\n",
    "         'C' : [10,20,50,100],\n",
    "         'degree' : [3,8],\n",
    "         'coef0' : [0.01,10,0.5],\n",
    "         'gamma': [1e-4, 1e-3, 0.01, 0.1, 0.2, 0.5, 0.6, 0.9]}\n",
    "\n",
    "modelsvr = SVR()\n",
    "\n",
    "grids = GridSearchCV(modelsvr,param,cv=5,n_jobs=-1,verbose=2)\n",
    "\n",
    "grids.fit(X_scaled, y_train.values.reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = grids.predict(X_scaled_test)\n",
    "correlation = pearsonr(test_predict, y_test.values.reshape(-1,))[0]\n",
    "print(\"Pearson correlation:\", correlation)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7b0227df9456bca28f69aef5d39629306c490f3d5d6e0ff9d2fd6f7d7f6a539"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
