========================

= TEAM =

SRI, Eric Yeh (yeh@ai.sri.com)
UBC, Eneko Agiree (e.agirre@ehu.es)

= DESCRIPTION OF RUN =

This run builds off of the techniques in run 1, introducing:
- Skip bigrams in BLEU form, per the ROUGE-S measure in Lin (2004).  The skip bigrams were placed in BLEU form, in order to measure pairwise precision.  Skip bigrams of up to distance 5 were employed.
- Skip bigram POS vector features for sentences with ten or less tokens, with a maximum distance of 3.

Run 1 incorporated the following:
- Several semantic similarity methods, based on different resource types and pooled using a Semantic Matrix (Fernando and Stevenson 2008).  The underlying resources include the WordNet Lin, WuP, and LCH WordNet similarity measures, the Lin thesaurus, and ESA over Wikipedia.  
- String edit (Levenshtein) distances, using the Semantic Matrix for pooling.
- Cosine overlap over lemmas.
- Soft BLEU score up to order 4 over lemmas.
- POS vector features, per Finch et al. (2005)
- Linear combinations of the above.

These were regressed using the LibSVM Support Vector Regression, with a CV tuned gamma of 1.0, using a radial basis kernel.

= TOOLS USED =

- Part of speech tagger
- Lemmatizer
- Distributional similarity
- Knowledge-based similarity

= RESOURCES USED =

- WordNet
- Wikipedia
- Lin's thesaurus

= METHOD TO COMBINE TOOLS AND RESOURCES =

Per the description, resource based methods (WordNet measures, Wikipedia, Lin's thesaurus) were pooled using Semantic Matrices to arrive at a number.  These, along with the POS vector features, were encoded as vectors and fed to the LibSVM Support Vector Regression package.

= COMMENTS =


