
Please include a description of your submission, following the format
below. 

Please don't modify lines starting with = unless instructed to do so.

Please delete lines starting with [. All lines starting with [ will be
ignored.

========================

= TEAM =

[Please include affiliation and name of first author]
UOW 
University of Wolverhampton, Miguel Angel Rios Gaona.

= DESCRIPTION OF RUN =

[Please include a short paragraph describing your method for the run]

= TOOLS USED =

[Please keep those tools that you used, delete those you did not use, and add more lines if needed]

* Part of speech tagger
* Lemmatizer
* Chunker
* Semantic Role Labeling
* Distributional similarity
* Named Entity recognition

= RESOURCES USED =

[Please keep those resources that you used, delete those you did not use, and add more lines if needed]

We use the score of lexical and semantic similarity metrics as features to train a Machine Learning algorithm. The Machine Learning algorithm is a Support Vector Machine (SVM) for regression.  The similarity metrics are: i) cosine similarity with a bag-of-tokens, ii) Precision, Recall and F-Measure with content words iii) modified BlEU for Chunks, iv) Named Entities and v) Semantic Role Labels. The cosine similarity with a bag-of-tokens computes the similarity between different bags of tokens such as words, lemmas and PoS.  The Precision, Recall and F-Measure use only the content words of sentences to compute the similarity. The modified BLEU uses chunk tags as input instead of words. The Named Entities metric groups entities by type and compares them with the cosine metric, but if the surface form of the entities is different the metric retrieves similar words from the Lin's thesaurus to expand the bag-of-words of the entities. The Semantic Role Labels metric automatically aligns predicates and arguments between sentences based on the content and type of arguments and the Lin's thesaurus, then the score of the semantic metric is based on recall.
For this run we train the parameters of the SVM with a genetic algorithm, and we use only the Semantic Role Labels metric as a feature.

* Lin's thesaurus

= METHOD TO COMBINE TOOLS AND RESOURCES =

[Please summarize the method to combine the tools and resources, mentioning whether it's heuristic, or uses machine learning, etc.]

The tools used are:
1 TreeTagger (http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/)
2 SENNA parser (http://ml.nec-labs.com/senna/)
2 LIBSVM (http://www.csie.ntu.edu.tw/~cjlin/libsvm/)

First, we use the above tools to preprocess the data to extract: words, lemmas, PoS, chunks, Named Entities and Semantic Role Labels. Second, we compute the similarity between sentences over the train and test datasets. Third, with the previous similarity scores over the training dataset we train the SVM for Regression. Then, we predict the scores over the test dataset.

For the feature extraction the lexical metrics use words, lemmas and PoS. The BLEU modification uses chunks tags as input. The named entities metric uses the tags to group the same type of entities and the metric adds similar words (extracted from the Lin's thesaurus) to allow synonym entities. The Semantic Roles Labels metric uses the tags to align the predicates and arguments, but it also allows the matching of synonym predicates by using the combination of the Lin's thesaurus and the content of the arguments of both sentences to match similar verbs.

= COMMENTS =

[Please include any comment you might have to improve the task in the future]
